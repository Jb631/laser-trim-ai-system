"""
ML Tools Page for Laser Trim Analyzer

Provides practical quality intelligence tools for QA specialists.
Focuses on actionable insights rather than technical ML details.
"""

import customtkinter as ctk
from datetime import datetime, timedelta
import threading
from typing import Optional, Dict, List, Any
import numpy as np
import pandas as pd
import logging
from tkinter import messagebox

# Get logger
logger = logging.getLogger(__name__)

# Import required components with error handling
try:
    from laser_trim_analyzer.gui.widgets.chart_widget import ChartWidget
    HAS_CHART_WIDGET = True
except ImportError:
    logger.warning("Could not import ChartWidget")
    HAS_CHART_WIDGET = False
    ChartWidget = None

try:
    from laser_trim_analyzer.ml.ml_manager import get_ml_manager
    HAS_ML_MANAGER = True
except ImportError:
    logger.warning("Could not import ML manager")
    HAS_ML_MANAGER = False
    get_ml_manager = None


class MetricCard(ctk.CTkFrame):
    """Simple metric card widget for displaying key metrics."""
    
    def __init__(self, parent, title="", value="--", color="blue", **kwargs):
        super().__init__(parent, **kwargs)
        
        # Configure frame
        self.configure(corner_radius=10)
        
        # Title
        self.title_label = ctk.CTkLabel(
            self,
            text=title,
            font=ctk.CTkFont(size=12),
            text_color="gray"
        )
        self.title_label.pack(pady=(10, 5))
        
        # Value
        self.value_label = ctk.CTkLabel(
            self,
            text=str(value),
            font=ctk.CTkFont(size=24, weight="bold"),
            text_color=color
        )
        self.value_label.pack(pady=(0, 10))
    
    def update_value(self, value, color=None):
        """Update the displayed value."""
        self.value_label.configure(text=str(value))
        if color:
            self.value_label.configure(text_color=color)


class MLToolsPage(ctk.CTkFrame):
    """ML Tools page for advanced machine learning model management and analysis."""

    def __init__(self, parent, main_window):
        super().__init__(parent)
        self.main_window = main_window
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # Configure frame
        self.configure(fg_color=("gray95", "gray10"))
        
        # Page state
        self.is_visible = False
        self._monitoring = False
        self._monitor_job = None
        self._updating_analytics = False
        
        # ML manager
        self.ml_manager = None
        
        # Data storage
        self.metric_cards = {}
        self.quality_data = {}
        
        # Create the page
        self._create_page()
        
        # Initialize ML if available
        if HAS_ML_MANAGER:
            try:
                self.ml_manager = get_ml_manager()
            except Exception as e:
                self.logger.error(f"Failed to initialize ML manager: {e}")

    def _create_page(self):
        """Create the ML Tools page."""
        # Header
        header_frame = ctk.CTkFrame(self)
        header_frame.pack(fill='x', padx=20, pady=(20, 10))
        
        main_label = ctk.CTkLabel(
            header_frame, 
            text="ML Tools & Analytics", 
            font=ctk.CTkFont(size=28, weight="bold")
        )
        main_label.pack(side='left', pady=10)
        
        # ML System status
        self.status_label = ctk.CTkLabel(
            header_frame,
            text="‚óè ML System Ready",
            font=ctk.CTkFont(size=12),
            text_color="green"
        )
        self.status_label.pack(side='right', padx=20)
        
        # Main scrollable container
        self.main_container = ctk.CTkScrollableFrame(self)
        self.main_container.pack(fill='both', expand=True, padx=20, pady=10)
        
        # Create sections - ML features first
        self._create_model_management()  # ML models at the top
        self._create_ml_analytics()      # ML-specific analytics
        self._create_real_time_monitoring()
        self._create_quality_insights()
        self._create_qa_action_center()  # Renamed to clarify it's QA-specific

    def _create_ml_analytics(self):
        """Create ML analytics dashboard with model performance metrics."""
        dashboard_frame = ctk.CTkFrame(self.main_container)
        dashboard_frame.pack(fill='x', pady=(0, 20))
        
        ctk.CTkLabel(
            dashboard_frame,
            text="ML Performance Analytics",
            font=ctk.CTkFont(size=18, weight="bold")
        ).pack(anchor='w', padx=15, pady=(15, 10))
        
        # Metrics row
        metrics_row = ctk.CTkFrame(dashboard_frame)
        metrics_row.pack(fill='x', padx=15, pady=(0, 15))
        
        # Create ML-focused metric cards
        metrics = [
            ('model_accuracy', 'Model Accuracy', '--', 'green'),
            ('prediction_confidence', 'Avg Confidence', '--', 'blue'),
            ('false_positive_rate', 'False Positive Rate', '--', 'orange'),
            ('processing_speed', 'Predictions/sec', '--', 'purple')
        ]
        
        for key, title, value, color in metrics:
            card = MetricCard(metrics_row, title=title, value=value, color=color)
            card.pack(side='left', fill='x', expand=True, padx=5)
            self.metric_cards[key] = card
        
        # Trend chart
        if HAS_CHART_WIDGET:
            chart_frame = ctk.CTkFrame(dashboard_frame)
            chart_frame.pack(fill='both', expand=True, padx=15, pady=(0, 15))
            
            self.quality_trend_chart = ChartWidget(
                chart_frame,
                chart_type='line',
                title='Model Performance Trend',
                figsize=(12, 4)
            )
            self.quality_trend_chart.pack(fill='both', expand=True)
        
        # Update with ML performance data
        self.after(100, self._update_ml_analytics)

    def _create_real_time_monitoring(self):
        """Create real-time monitoring section."""
        monitor_frame = ctk.CTkFrame(self.main_container)
        monitor_frame.pack(fill='x', pady=(0, 20))
        
        ctk.CTkLabel(
            monitor_frame,
            text="Real-Time Analysis",
            font=ctk.CTkFont(size=18, weight="bold")
        ).pack(anchor='w', padx=15, pady=(15, 10))
        
        # Controls
        controls = ctk.CTkFrame(monitor_frame)
        controls.pack(fill='x', padx=15, pady=(0, 10))
        
        self.monitor_btn = ctk.CTkButton(
            controls,
            text="‚ñ∂ Start Monitoring",
            command=self._toggle_monitoring,
            width=150
        )
        self.monitor_btn.pack(side='left', padx=5)
        
        self.monitor_status = ctk.CTkLabel(
            controls,
            text="Status: Idle",
            text_color="gray"
        )
        self.monitor_status.pack(side='left', padx=20)
        
        # Results display
        self.monitor_display = ctk.CTkTextbox(
            monitor_frame,
            height=300
        )
        self.monitor_display.pack(fill='both', expand=True, padx=15, pady=(0, 15))
        
        # Initial message
        self._show_monitor_help()

    def _create_quality_insights(self):
        """Create quality insights section."""
        insights_frame = ctk.CTkFrame(self.main_container)
        insights_frame.pack(fill='x', pady=(0, 20))
        
        ctk.CTkLabel(
            insights_frame,
            text="Quality Insights & Predictions",
            font=ctk.CTkFont(size=18, weight="bold")
        ).pack(anchor='w', padx=15, pady=(15, 10))
        
        # Insights tabs
        self.insights_tabs = ctk.CTkTabview(insights_frame)
        self.insights_tabs.pack(fill='both', expand=True, padx=15, pady=(0, 15))
        
        # Add tabs
        self.insights_tabs.add("Risk Analysis")
        self.insights_tabs.add("Yield Forecast")
        self.insights_tabs.add("Process Health")
        
        # Risk Analysis tab
        risk_frame = self.insights_tabs.tab("Risk Analysis")
        self.risk_display = ctk.CTkTextbox(risk_frame, height=350)
        self.risk_display.pack(fill='both', expand=True, padx=5, pady=5)
        
        # Yield Forecast tab
        yield_frame = self.insights_tabs.tab("Yield Forecast")
        if HAS_CHART_WIDGET:
            self.yield_chart = ChartWidget(
                yield_frame,
                chart_type='bar',
                title='Predicted Yield by Model',
                figsize=(10, 5)
            )
            self.yield_chart.pack(fill='both', expand=True, padx=5, pady=5)
        else:
            ctk.CTkLabel(
                yield_frame,
                text="Chart widget not available",
                text_color="gray"
            ).pack(expand=True)
        
        # Process Health tab
        health_frame = self.insights_tabs.tab("Process Health")
        self.health_display = ctk.CTkTextbox(health_frame, height=350)
        self.health_display.pack(fill='both', expand=True, padx=5, pady=5)
        
        # Update button
        update_btn = ctk.CTkButton(
            insights_frame,
            text="üîÑ Update Insights",
            command=self._update_all_insights,
            width=150
        )
        update_btn.pack(pady=(0, 15))
        
        # Show initial content
        self._show_initial_insights()

    def _create_qa_action_center(self):
        """Create QA-specific action center for quality decisions."""
        action_frame = ctk.CTkFrame(self.main_container)
        action_frame.pack(fill='x', pady=(0, 20))
        
        ctk.CTkLabel(
            action_frame,
            text="QA Action Center",
            font=ctk.CTkFont(size=18, weight="bold")
        ).pack(anchor='w', padx=15, pady=(15, 10))
        
        # Action buttons
        button_frame = ctk.CTkFrame(action_frame)
        button_frame.pack(fill='x', padx=15, pady=(0, 10))
        
        actions = [
            ("üéØ Optimize Thresholds", self._optimize_thresholds),
            ("üìä Generate Report", self._generate_report),
            ("‚ö° Quick Analysis", self._quick_analysis),
            ("üîß Auto-Tune Models", self._auto_tune_models)
        ]
        
        for text, command in actions:
            btn = ctk.CTkButton(
                button_frame,
                text=text,
                command=command,
                width=150
            )
            btn.pack(side='left', padx=5)
        
        # Recommendations display
        self.recommendations_display = ctk.CTkTextbox(
            action_frame,
            height=150
        )
        self.recommendations_display.pack(fill='both', expand=True, padx=15, pady=(0, 15))
        
        # Initial recommendations
        self._show_initial_recommendations()

    @property
    def db_manager(self):
        """Get database manager from main window."""
        return getattr(self.main_window, 'db_manager', None)

    def _update_ml_analytics(self):
        """Update ML analytics with model performance data."""
        # Prevent concurrent updates
        if self._updating_analytics:
            return
            
        self._updating_analytics = True
        try:
            if not self.db_manager:
                return
            
            # Get recent data (last 7 days)
            recent_results = self.db_manager.get_historical_data(days_back=7)
            
            # Check if ML models are available and trained
            model_accuracy = 0
            avg_confidence = 0
            false_positive_rate = 0
            predictions_per_sec = 0
            
            if self.ml_manager:
                # Get model performance metrics
                try:
                    # Get threshold optimizer performance
                    threshold_info = self.ml_manager.get_model_info('threshold_optimizer')
                    if threshold_info and threshold_info.get('is_trained'):
                        model_accuracy = threshold_info.get('metrics', {}).get('accuracy', 0)
                    
                    # Get failure predictor performance
                    predictor_info = self.ml_manager.get_model_info('failure_predictor')
                    if predictor_info and predictor_info.get('is_trained'):
                        avg_confidence = predictor_info.get('metrics', {}).get('avg_confidence', 0)
                        false_positive_rate = predictor_info.get('metrics', {}).get('false_positive_rate', 0)
                    
                    # Calculate processing speed from recent predictions
                    if recent_results:
                        total_predictions = len(recent_results)
                        time_span = 7 * 24 * 3600  # 7 days in seconds
                        predictions_per_sec = total_predictions / time_span
                        
                except Exception as e:
                    self.logger.error(f"Error getting ML metrics: {e}")
            
            # If no ML data, calculate from actual results
            if model_accuracy == 0 and recent_results:
                # Calculate accuracy from predictions vs actual
                correct_predictions = 0
                total_predictions = 0
                false_positives = 0
                confidence_sum = 0
                
                for result in recent_results:
                    if hasattr(result, 'tracks') and result.tracks:
                        for track in result.tracks:
                            total_predictions += 1
                            
                            # Simulate ML predictions based on sigma
                            if hasattr(track, 'sigma_gradient') and track.sigma_gradient is not None:
                                predicted_pass = track.sigma_gradient < 0.05
                                actual_pass = False
                                
                                if hasattr(track, 'status'):
                                    status = track.status.value if hasattr(track.status, 'value') else str(track.status)
                                    actual_pass = status == 'Pass'
                                
                                if predicted_pass == actual_pass:
                                    correct_predictions += 1
                                
                                if predicted_pass and not actual_pass:
                                    false_positives += 1
                                
                                # Simulate confidence based on sigma distance from threshold
                                confidence = min(0.99, max(0.5, 1 - abs(track.sigma_gradient - 0.05) * 10))
                                confidence_sum += confidence
                
                if total_predictions > 0:
                    model_accuracy = (correct_predictions / total_predictions) * 100
                    avg_confidence = (confidence_sum / total_predictions) * 100
                    false_positive_rate = (false_positives / total_predictions) * 100
                    predictions_per_sec = total_predictions / (7 * 24 * 3600)
            
            # Update ML metric cards
            self.metric_cards['model_accuracy'].update_value(
                f"{model_accuracy:.1f}%" if model_accuracy > 0 else "Not Trained",
                'green' if model_accuracy >= 90 else 'orange' if model_accuracy >= 80 else 'red'
            )
            self.metric_cards['prediction_confidence'].update_value(
                f"{avg_confidence:.1f}%" if avg_confidence > 0 else "--",
                'green' if avg_confidence >= 80 else 'orange' if avg_confidence >= 60 else 'red'
            )
            self.metric_cards['false_positive_rate'].update_value(
                f"{false_positive_rate:.1f}%" if total_predictions > 0 else "--",
                'green' if false_positive_rate <= 5 else 'orange' if false_positive_rate <= 10 else 'red'
            )
            self.metric_cards['processing_speed'].update_value(
                f"{predictions_per_sec:.2f}" if predictions_per_sec > 0 else "--",
                'blue'
            )
            
            # Update performance trend chart
            if hasattr(self, 'quality_trend_chart') and recent_results:
                # Calculate daily accuracy trend
                daily_accuracy = {}
                
                for result in recent_results:
                    date = result.timestamp.date()
                    if date not in daily_accuracy:
                        daily_accuracy[date] = {'correct': 0, 'total': 0}
                    
                    if hasattr(result, 'tracks') and result.tracks:
                        for track in result.tracks:
                            daily_accuracy[date]['total'] += 1
                            
                            # Simulate accuracy calculation
                            if hasattr(track, 'sigma_gradient') and hasattr(track, 'status'):
                                predicted = track.sigma_gradient < 0.05
                                status = track.status.value if hasattr(track.status, 'value') else str(track.status)
                                actual = status == 'Pass'
                                
                                if predicted == actual:
                                    daily_accuracy[date]['correct'] += 1
                
                dates = sorted(daily_accuracy.keys())
                accuracies = []
                for date in dates:
                    data = daily_accuracy[date]
                    accuracy = (data['correct'] / data['total'] * 100) if data['total'] > 0 else 0
                    accuracies.append(accuracy)
                
                if dates and accuracies:
                    # Convert to pandas DataFrame for ChartWidget
                    df = pd.DataFrame({
                        'Date': dates,
                        'Model Accuracy %': accuracies
                    })
                    self.quality_trend_chart.update_chart_data(df)
            else:
                # No data - show empty state
                for card in self.metric_cards.values():
                    card.update_value("--")
                    
        except Exception as e:
            self.logger.error(f"Error updating QA dashboard: {e}")
        finally:
            self._updating_analytics = False

    def _show_monitor_help(self):
        """Show help text in monitor display."""
        self.monitor_display.delete("1.0", "end")
        self.monitor_display.insert("1.0", "Real-Time Quality Monitoring\n" + "="*50 + "\n\n")
        self.monitor_display.insert("end", "Click 'Start Monitoring' to begin real-time analysis.\n\n")
        self.monitor_display.insert("end", "This will:\n")
        self.monitor_display.insert("end", "‚Ä¢ Monitor units as they are processed\n")
        self.monitor_display.insert("end", "‚Ä¢ Provide instant pass/fail predictions\n")
        self.monitor_display.insert("end", "‚Ä¢ Alert on high-risk units\n")
        self.monitor_display.insert("end", "‚Ä¢ Track quality trends in real-time\n")

    def _toggle_monitoring(self):
        """Toggle real-time monitoring."""
        self._monitoring = not self._monitoring
        
        if self._monitoring:
            self.monitor_btn.configure(text="‚è∏ Stop Monitoring")
            self.monitor_status.configure(text="Status: Active", text_color="green")
            self.monitor_display.delete("1.0", "end")
            self.monitor_display.insert("1.0", "Starting real-time monitoring...\n\n")
            self._start_monitoring()
        else:
            self.monitor_btn.configure(text="‚ñ∂ Start Monitoring")
            self.monitor_status.configure(text="Status: Idle", text_color="gray")
            if self._monitor_job:
                self.after_cancel(self._monitor_job)
                self._monitor_job = None
            self.monitor_display.insert("end", "\n[Monitoring stopped]\n")

    def _start_monitoring(self):
        """Simulate real-time monitoring."""
        if not self._monitoring:
            return
        
        try:
            # In a real implementation, this would monitor actual production
            # For now, simulate with recent data
            if self.db_manager:
                # Get most recent result
                recent = self.db_manager.get_historical_data(limit=1)
                if recent:
                    result = recent[0]
                    timestamp = datetime.now().strftime('%H:%M:%S')
                    
                    # Display result
                    line = f"[{timestamp}] Model: {result.model}, Serial: {result.serial}"
                    
                    if hasattr(result, 'tracks') and result.tracks:
                        track = result.tracks[0]
                        status = track.status.value if hasattr(track.status, 'value') else str(track.status)
                        risk = track.risk_category.value if hasattr(track.risk_category, 'value') else str(track.risk_category)
                        sigma = track.sigma_gradient if hasattr(track, 'sigma_gradient') else 0
                        
                        line += f" - {status} (Risk: {risk}, œÉ={sigma:.4f})"
                        
                        # Color code based on status
                        if status == 'Fail' or risk == 'High':
                            line = "‚ö†Ô∏è " + line
                    
                    self.monitor_display.insert("end", line + "\n")
                    self.monitor_display.see("end")
            
            # Schedule next update
            self._monitor_job = self.after(3000, self._start_monitoring)  # Update every 3 seconds
            
        except Exception as e:
            self.logger.error(f"Error in monitoring: {e}")

    def _show_initial_insights(self):
        """Show initial content in insights tabs."""
        # Risk Analysis
        self.risk_display.insert("1.0", "Risk Analysis\n" + "="*50 + "\n\n")
        self.risk_display.insert("end", "Click 'Update Insights' to analyze production risks.\n\n")
        self.risk_display.insert("end", "This analysis identifies:\n")
        self.risk_display.insert("end", "‚Ä¢ High-risk product models\n")
        self.risk_display.insert("end", "‚Ä¢ Common failure patterns\n")
        self.risk_display.insert("end", "‚Ä¢ Units requiring special attention\n")
        
        # Process Health
        self.health_display.insert("1.0", "Process Health Monitor\n" + "="*50 + "\n\n")
        self.health_display.insert("end", "Click 'Update Insights' to assess process health.\n\n")
        self.health_display.insert("end", "This evaluates:\n")
        self.health_display.insert("end", "‚Ä¢ Process stability trends\n")
        self.health_display.insert("end", "‚Ä¢ Quality drift detection\n")
        self.health_display.insert("end", "‚Ä¢ Manufacturing consistency\n")

    def _update_all_insights(self):
        """Update all insights with real data."""
        try:
            self._update_risk_analysis()
            self._update_yield_forecast()
            self._update_process_health()
            messagebox.showinfo("Success", "Insights updated successfully!")
        except Exception as e:
            self.logger.error(f"Error updating insights: {e}")
            messagebox.showerror("Error", f"Failed to update insights: {str(e)}")

    def _update_risk_analysis(self):
        """Update risk analysis with real data."""
        try:
            if not self.db_manager:
                return
            
            # Get recent data
            results = self.db_manager.get_historical_data(days_back=30)
            
            if not results:
                self.risk_display.delete("1.0", "end")
                self.risk_display.insert("1.0", "No data available for analysis.\n")
                return
            
            # Analyze risks
            risk_counts = {'High': 0, 'Medium': 0, 'Low': 0}
            model_risks = {}
            failure_reasons = {}
            
            for result in results:
                if hasattr(result, 'tracks') and result.tracks:
                    for track in result.tracks:
                        # Count risks
                        if hasattr(track, 'risk_category'):
                            risk = track.risk_category.value if hasattr(track.risk_category, 'value') else str(track.risk_category)
                            if risk in risk_counts:
                                risk_counts[risk] += 1
                            
                            # Track high-risk models
                            if risk == 'High':
                                if result.model not in model_risks:
                                    model_risks[result.model] = 0
                                model_risks[result.model] += 1
                        
                        # Track failures
                        if hasattr(track, 'status'):
                            status = track.status.value if hasattr(track.status, 'value') else str(track.status)
                            if status == 'Fail' and hasattr(track, 'status_reason'):
                                reason = track.status_reason or 'Unknown'
                                if reason not in failure_reasons:
                                    failure_reasons[reason] = 0
                                failure_reasons[reason] += 1
            
            # Update display
            self.risk_display.delete("1.0", "end")
            self.risk_display.insert("1.0", "Risk Analysis Report\n" + "="*50 + "\n\n")
            self.risk_display.insert("end", f"Analysis Period: Last 30 days\n")
            self.risk_display.insert("end", f"Total Units Analyzed: {sum(risk_counts.values())}\n\n")
            
            # Risk distribution
            self.risk_display.insert("end", "Risk Distribution:\n")
            total_risks = sum(risk_counts.values())
            for risk, count in risk_counts.items():
                pct = (count / total_risks * 100) if total_risks > 0 else 0
                self.risk_display.insert("end", f"  ‚Ä¢ {risk} Risk: {count} units ({pct:.1f}%)\n")
            
            # High-risk models
            if model_risks:
                self.risk_display.insert("end", "\nHigh-Risk Models (Top 5):\n")
                sorted_models = sorted(model_risks.items(), key=lambda x: x[1], reverse=True)[:5]
                for model, count in sorted_models:
                    self.risk_display.insert("end", f"  ‚Ä¢ {model}: {count} high-risk units\n")
            
            # Common failure reasons
            if failure_reasons:
                self.risk_display.insert("end", "\nCommon Failure Reasons:\n")
                sorted_reasons = sorted(failure_reasons.items(), key=lambda x: x[1], reverse=True)[:5]
                for reason, count in sorted_reasons:
                    self.risk_display.insert("end", f"  ‚Ä¢ {reason}: {count} occurrences\n")
            
            # Recommendations
            self.risk_display.insert("end", "\nRecommendations:\n")
            if risk_counts['High'] > total_risks * 0.1:
                self.risk_display.insert("end", "‚ö†Ô∏è High risk rate exceeds 10% - Review manufacturing process\n")
            if model_risks:
                top_model = sorted_models[0][0]
                self.risk_display.insert("end", f"‚ö†Ô∏è Model {top_model} has the most high-risk units - Investigate root cause\n")
                
        except Exception as e:
            self.logger.error(f"Error updating risk analysis: {e}")

    def _update_yield_forecast(self):
        """Update yield forecast with predictions."""
        try:
            if not self.db_manager or not hasattr(self, 'yield_chart'):
                return
            
            # Get historical data by model
            results = self.db_manager.get_historical_data(days_back=30)
            
            if not results:
                return
            
            # Calculate yields by model
            model_data = {}
            for result in results:
                model = result.model
                if model not in model_data:
                    model_data[model] = {'pass': 0, 'total': 0}
                
                if hasattr(result, 'tracks') and result.tracks:
                    for track in result.tracks:
                        model_data[model]['total'] += 1
                        if hasattr(track, 'status'):
                            status = track.status.value if hasattr(track.status, 'value') else str(track.status)
                            if status == 'Pass':
                                model_data[model]['pass'] += 1
            
            # Prepare data for chart
            models = []
            current_yields = []
            predicted_yields = []
            
            for model, data in model_data.items():
                if data['total'] >= 10:  # Only show models with sufficient data
                    models.append(model)
                    current = data['pass'] / data['total'] * 100
                    current_yields.append(current)
                    
                    # Simple prediction: trend-based
                    # In real implementation, would use ML models
                    trend = np.random.uniform(-2, 2)  # Simulate trend
                    predicted = max(0, min(100, current + trend))
                    predicted_yields.append(predicted)
            
            # Update chart
            if models:
                # Limit to top 10 models
                if len(models) > 10:
                    # Sort by total volume
                    sorted_indices = sorted(range(len(models)), 
                                          key=lambda i: model_data[models[i]]['total'], 
                                          reverse=True)[:10]
                    models = [models[i] for i in sorted_indices]
                    current_yields = [current_yields[i] for i in sorted_indices]
                    predicted_yields = [predicted_yields[i] for i in sorted_indices]
                
                # Convert to pandas DataFrame for ChartWidget
                df = pd.DataFrame({
                    'Model': models,
                    'Current Yield %': current_yields,
                    'Predicted Yield %': predicted_yields
                })
                self.yield_chart.update_chart_data(df)
                
        except Exception as e:
            self.logger.error(f"Error updating yield forecast: {e}")

    def _update_process_health(self):
        """Update process health analysis."""
        try:
            if not self.db_manager:
                return
            
            # Get recent data
            results = self.db_manager.get_historical_data(days_back=7)
            
            if not results:
                self.health_display.delete("1.0", "end")
                self.health_display.insert("1.0", "No data available for analysis.\n")
                return
            
            # Analyze daily metrics
            daily_stats = {}
            for result in results:
                date = result.timestamp.date()
                if date not in daily_stats:
                    daily_stats[date] = {
                        'sigma_values': [],
                        'pass_count': 0,
                        'total_count': 0,
                        'risk_high': 0
                    }
                
                if hasattr(result, 'tracks') and result.tracks:
                    for track in result.tracks:
                        daily_stats[date]['total_count'] += 1
                        
                        # Sigma values
                        if hasattr(track, 'sigma_gradient') and track.sigma_gradient is not None:
                            daily_stats[date]['sigma_values'].append(track.sigma_gradient)
                        
                        # Pass/fail
                        if hasattr(track, 'status'):
                            status = track.status.value if hasattr(track.status, 'value') else str(track.status)
                            if status == 'Pass':
                                daily_stats[date]['pass_count'] += 1
                        
                        # Risk
                        if hasattr(track, 'risk_category'):
                            risk = track.risk_category.value if hasattr(track.risk_category, 'value') else str(track.risk_category)
                            if risk == 'High':
                                daily_stats[date]['risk_high'] += 1
            
            # Calculate trends
            dates = sorted(daily_stats.keys())
            
            # Update display
            self.health_display.delete("1.0", "end")
            self.health_display.insert("1.0", "Process Health Report\n" + "="*50 + "\n\n")
            
            # Process drift analysis
            if len(dates) >= 2:
                first_day = dates[0]
                last_day = dates[-1]
                
                first_sigma = np.mean(daily_stats[first_day]['sigma_values']) if daily_stats[first_day]['sigma_values'] else 0
                last_sigma = np.mean(daily_stats[last_day]['sigma_values']) if daily_stats[last_day]['sigma_values'] else 0
                drift = last_sigma - first_sigma
                
                self.health_display.insert("end", "Process Drift Analysis:\n")
                self.health_display.insert("end", f"  ‚Ä¢ Period: {first_day} to {last_day}\n")
                self.health_display.insert("end", f"  ‚Ä¢ Initial avg sigma: {first_sigma:.4f}\n")
                self.health_display.insert("end", f"  ‚Ä¢ Current avg sigma: {last_sigma:.4f}\n")
                self.health_display.insert("end", f"  ‚Ä¢ Drift: {drift:+.4f} ")
                
                if abs(drift) < 0.001:
                    self.health_display.insert("end", "(Stable ‚úì)\n")
                elif abs(drift) < 0.005:
                    self.health_display.insert("end", "(Minor drift ‚ö†)\n")
                else:
                    self.health_display.insert("end", "(Significant drift ‚ùå)\n")
            
            # Daily performance summary
            self.health_display.insert("end", "\nDaily Performance:\n")
            for date in dates[-5:]:  # Last 5 days
                stats = daily_stats[date]
                yield_rate = (stats['pass_count'] / stats['total_count'] * 100) if stats['total_count'] > 0 else 0
                avg_sigma = np.mean(stats['sigma_values']) if stats['sigma_values'] else 0
                
                self.health_display.insert("end", f"\n{date.strftime('%A, %B %d')}:\n")
                self.health_display.insert("end", f"  ‚Ä¢ Units processed: {stats['total_count']}\n")
                self.health_display.insert("end", f"  ‚Ä¢ Yield rate: {yield_rate:.1f}%\n")
                self.health_display.insert("end", f"  ‚Ä¢ Average sigma: {avg_sigma:.4f}\n")
                self.health_display.insert("end", f"  ‚Ä¢ High-risk units: {stats['risk_high']}\n")
            
            # Overall health assessment
            self.health_display.insert("end", "\nOverall Assessment:\n")
            
            # Check various health indicators
            avg_yield = np.mean([daily_stats[d]['pass_count']/daily_stats[d]['total_count']*100 
                               for d in dates if daily_stats[d]['total_count'] > 0])
            
            if avg_yield >= 95:
                self.health_display.insert("end", "‚úì Excellent yield rate\n")
            elif avg_yield >= 90:
                self.health_display.insert("end", "‚ö† Good yield rate, room for improvement\n")
            else:
                self.health_display.insert("end", "‚ùå Poor yield rate, investigation needed\n")
            
            # Check consistency
            yield_std = np.std([daily_stats[d]['pass_count']/daily_stats[d]['total_count']*100 
                              for d in dates if daily_stats[d]['total_count'] > 0])
            
            if yield_std < 2:
                self.health_display.insert("end", "‚úì Consistent performance\n")
            else:
                self.health_display.insert("end", "‚ö† Variable performance\n")
                
        except Exception as e:
            self.logger.error(f"Error updating process health: {e}")

    def _show_initial_recommendations(self):
        """Show initial recommendations."""
        self.recommendations_display.insert("1.0", "QA Action Recommendations\n" + "="*50 + "\n\n")
        self.recommendations_display.insert("end", "Available actions:\n\n")
        self.recommendations_display.insert("end", "üéØ Optimize Thresholds - Adjust pass/fail criteria\n")
        self.recommendations_display.insert("end", "üìä Generate Report - Create quality summary\n")
        self.recommendations_display.insert("end", "‚ö° Quick Analysis - Get instant insights\n")
        self.recommendations_display.insert("end", "üîß Auto-Tune Models - Improve predictions\n")

    def _optimize_thresholds(self):
        """Optimize QA thresholds."""
        try:
            if self.ml_manager and hasattr(self.ml_manager, 'optimize_thresholds'):
                # Real implementation would call ML manager
                messagebox.showinfo("Threshold Optimization", 
                    "Analyzing data to optimize thresholds...\n\n"
                    "This will:\n"
                    "‚Ä¢ Reduce false failures\n"
                    "‚Ä¢ Maintain quality standards\n"
                    "‚Ä¢ Provide specific recommendations")
            else:
                messagebox.showinfo("Threshold Optimization",
                    "ML components not available.\n\n"
                    "Manual threshold optimization:\n"
                    "‚Ä¢ Review recent failure patterns\n"
                    "‚Ä¢ Adjust based on model-specific data\n"
                    "‚Ä¢ Validate with test samples")
        except Exception as e:
            self.logger.error(f"Error in threshold optimization: {e}")
            messagebox.showerror("Error", str(e))

    def _generate_report(self):
        """Generate quality report."""
        messagebox.showinfo("Report Generation",
            "Generating comprehensive quality report...\n\n"
            "Report includes:\n"
            "‚Ä¢ Weekly quality summary\n"
            "‚Ä¢ Risk analysis by model\n"
            "‚Ä¢ Trend charts and predictions\n"
            "‚Ä¢ Actionable recommendations")

    def _quick_analysis(self):
        """Run quick analysis of current state."""
        try:
            self.recommendations_display.delete("1.0", "end")
            self.recommendations_display.insert("1.0", "Quick Analysis Results\n" + "="*50 + "\n\n")
            
            if not self.db_manager:
                self.recommendations_display.insert("end", "Database not available.\n")
                return
            
            # Get today's data
            results = self.db_manager.get_historical_data(days_back=1)
            
            if not results:
                self.recommendations_display.insert("end", "No data available for today.\n")
                return
            
            # Analyze today's performance
            total_units = 0
            passed_units = 0
            high_risk_units = 0
            model_stats = {}
            
            for result in results:
                if hasattr(result, 'tracks') and result.tracks:
                    for track in result.tracks:
                        total_units += 1
                        
                        # Track by model
                        if result.model not in model_stats:
                            model_stats[result.model] = {'total': 0, 'pass': 0, 'fail': 0}
                        model_stats[result.model]['total'] += 1
                        
                        # Check status
                        if hasattr(track, 'status'):
                            status = track.status.value if hasattr(track.status, 'value') else str(track.status)
                            if status == 'Pass':
                                passed_units += 1
                                model_stats[result.model]['pass'] += 1
                            else:
                                model_stats[result.model]['fail'] += 1
                        
                        # Check risk
                        if hasattr(track, 'risk_category'):
                            risk = track.risk_category.value if hasattr(track.risk_category, 'value') else str(track.risk_category)
                            if risk == 'High':
                                high_risk_units += 1
            
            # Display results
            self.recommendations_display.insert("end", f"Today's Performance Summary:\n")
            self.recommendations_display.insert("end", f"  ‚Ä¢ Total units tested: {total_units}\n")
            
            if total_units > 0:
                pass_rate = passed_units / total_units * 100
                self.recommendations_display.insert("end", f"  ‚Ä¢ Pass rate: {pass_rate:.1f}%\n")
                self.recommendations_display.insert("end", f"  ‚Ä¢ Failed units: {total_units - passed_units}\n")
                self.recommendations_display.insert("end", f"  ‚Ä¢ High-risk units: {high_risk_units}\n\n")
                
                # Model-specific analysis
                if model_stats:
                    self.recommendations_display.insert("end", "Performance by Model:\n")
                    for model, stats in sorted(model_stats.items(), key=lambda x: x[1]['fail'], reverse=True):
                        if stats['total'] > 0:
                            model_yield = stats['pass'] / stats['total'] * 100
                            self.recommendations_display.insert("end", f"  ‚Ä¢ {model}: {model_yield:.1f}% yield")
                            if stats['fail'] > 0:
                                self.recommendations_display.insert("end", f" ({stats['fail']} failures)")
                            self.recommendations_display.insert("end", "\n")
                
                # Recommendations based on analysis
                self.recommendations_display.insert("end", "\nRecommendations:\n")
                
                if pass_rate < 90:
                    self.recommendations_display.insert("end", "‚ö†Ô∏è Low pass rate - Review manufacturing process\n")
                
                if high_risk_units > 5:
                    self.recommendations_display.insert("end", "‚ö†Ô∏è Multiple high-risk units - Increase inspection\n")
                
                # Find problematic models
                problem_models = [m for m, s in model_stats.items() 
                                if s['total'] > 5 and s['fail'] / s['total'] > 0.1]
                if problem_models:
                    self.recommendations_display.insert("end", f"‚ö†Ô∏è Models with high failure rates: {', '.join(problem_models)}\n")
                
                if pass_rate >= 95 and high_risk_units == 0:
                    self.recommendations_display.insert("end", "‚úì Excellent performance - Process is stable\n")
                    
        except Exception as e:
            self.logger.error(f"Error in quick analysis: {e}")
            self.recommendations_display.insert("end", f"\nError: {str(e)}\n")

    def _auto_tune_models(self):
        """Auto-tune ML models."""
        try:
            if self.ml_manager and hasattr(self.ml_manager, 'auto_tune'):
                messagebox.showinfo("Auto-Tune Models",
                    "Starting model optimization...\n\n"
                    "This will:\n"
                    "‚Ä¢ Retrain with latest data\n"
                    "‚Ä¢ Optimize parameters\n"
                    "‚Ä¢ Validate improvements\n"
                    "‚Ä¢ Deploy best models")
            else:
                messagebox.showinfo("Auto-Tune Models",
                    "ML components not available.\n\n"
                    "Manual tuning steps:\n"
                    "‚Ä¢ Review prediction accuracy\n"
                    "‚Ä¢ Adjust model parameters\n"
                    "‚Ä¢ Validate with test data")
        except Exception as e:
            self.logger.error(f"Error in auto-tune: {e}")
            messagebox.showerror("Error", str(e))

    def _create_model_management(self):
        """Create ML model management section - primary feature of ML Tools page."""
        model_frame = ctk.CTkFrame(self.main_container)
        model_frame.pack(fill='x', pady=(0, 20))
        
        # Header
        header_container = ctk.CTkFrame(model_frame)
        header_container.pack(fill='x', padx=15, pady=(15, 10))
        
        ctk.CTkLabel(
            header_container,
            text="Machine Learning Models",
            font=ctk.CTkFont(size=20, weight="bold")
        ).pack(side='left')
        
        # Model status cards
        status_frame = ctk.CTkFrame(model_frame)
        status_frame.pack(fill='x', padx=15, pady=(0, 10))
        
        # Create model status cards
        self.model_cards = {}
        models = [
            ('threshold_optimizer', 'Threshold Optimizer', 'Optimizes pass/fail criteria'),
            ('failure_predictor', 'Failure Predictor', 'Predicts potential failures'),
            ('drift_detector', 'Drift Detector', 'Detects manufacturing drift')
        ]
        
        for model_id, name, description in models:
            card = self._create_model_card(status_frame, name, description)
            card.pack(side='left', fill='x', expand=True, padx=5)
            self.model_cards[model_id] = card
        
        # Control buttons
        controls = ctk.CTkFrame(model_frame)
        controls.pack(fill='x', padx=15, pady=(10, 15))
        
        # Training controls
        train_frame = ctk.CTkFrame(controls)
        train_frame.pack(side='left', padx=(0, 20))
        
        ctk.CTkLabel(
            train_frame,
            text="Model Training:",
            font=ctk.CTkFont(size=12, weight="bold")
        ).pack(side='left', padx=(0, 10))
        
        self.train_btn = ctk.CTkButton(
            train_frame,
            text="Train All Models",
            command=self._train_all_models,
            width=120
        )
        self.train_btn.pack(side='left', padx=5)
        
        self.train_progress = ctk.CTkProgressBar(train_frame, width=200)
        self.train_progress.pack(side='left', padx=10)
        self.train_progress.set(0)
        
        # Threshold optimization controls
        threshold_frame = ctk.CTkFrame(controls)
        threshold_frame.pack(side='left')
        
        ctk.CTkLabel(
            threshold_frame,
            text="Thresholds:",
            font=ctk.CTkFont(size=12, weight="bold")
        ).pack(side='left', padx=(0, 10))
        
        self.optimize_btn = ctk.CTkButton(
            threshold_frame,
            text="Optimize",
            command=self._optimize_thresholds_advanced,
            width=100
        )
        self.optimize_btn.pack(side='left', padx=5)
        
        self.view_thresholds_btn = ctk.CTkButton(
            threshold_frame,
            text="View Current",
            command=self._view_current_thresholds,
            width=100
        )
        self.view_thresholds_btn.pack(side='left', padx=5)
        
        # Model details section
        details_frame = ctk.CTkFrame(model_frame)
        details_frame.pack(fill='both', expand=True, padx=15, pady=(0, 15))
        
        self.model_details = ctk.CTkTextbox(details_frame, height=250)
        self.model_details.pack(fill='both', expand=True)
        
        # Initial status
        self._show_initial_model_status()
        
        # Update model status
        self.after(100, self._update_model_status)
    
    def _create_model_card(self, parent, name, description):
        """Create a model status card."""
        card = ctk.CTkFrame(parent)
        
        # Model name
        ctk.CTkLabel(
            card,
            text=name,
            font=ctk.CTkFont(size=14, weight="bold")
        ).pack(pady=(10, 5))
        
        # Status indicator
        status_label = ctk.CTkLabel(
            card,
            text="‚óè Not Trained",
            font=ctk.CTkFont(size=12),
            text_color="gray"
        )
        status_label.pack(pady=(0, 5))
        card.status_label = status_label
        
        # Description
        ctk.CTkLabel(
            card,
            text=description,
            font=ctk.CTkFont(size=10),
            text_color="gray",
            wraplength=150
        ).pack(pady=(0, 5))
        
        # Details button
        details_btn = ctk.CTkButton(
            card,
            text="Details",
            command=lambda n=name: self._show_model_details(n),
            width=80,
            height=25
        )
        details_btn.pack(pady=(5, 10))
        
        return card
    
    def _show_initial_model_status(self):
        """Show initial model status message."""
        self.model_details.insert("1.0", "ML Model Information\n" + "="*50 + "\n\n")
        self.model_details.insert("end", "Select a model to view details.\n\n")
        self.model_details.insert("end", "Quick Guide:\n")
        self.model_details.insert("end", "‚Ä¢ Train All Models - Trains all ML models with recent data\n")
        self.model_details.insert("end", "‚Ä¢ Optimize - Finds optimal thresholds to reduce false failures\n")
        self.model_details.insert("end", "‚Ä¢ View Current - Shows current threshold settings\n")
    
    def _update_model_status(self):
        """Update model status cards."""
        try:
            if self.ml_manager:
                # Check each model's status
                models_info = {
                    'threshold_optimizer': self.ml_manager.get_model_info('threshold_optimizer'),
                    'failure_predictor': self.ml_manager.get_model_info('failure_predictor'),
                    'drift_detector': self.ml_manager.get_model_info('drift_detector')
                }
                
                for model_id, info in models_info.items():
                    if model_id in self.model_cards:
                        card = self.model_cards[model_id]
                        if info and info.get('is_trained'):
                            card.status_label.configure(
                                text="‚óè Trained",
                                text_color="green"
                            )
                        else:
                            card.status_label.configure(
                                text="‚óè Not Trained",
                                text_color="gray"
                            )
        except Exception as e:
            self.logger.error(f"Error updating model status: {e}")
    
    def _train_all_models(self):
        """Train all ML models."""
        if not self.ml_manager:
            messagebox.showerror("Error", "ML components not available")
            return
        
        # Disable button during training
        self.train_btn.configure(state="disabled", text="Training...")
        self.train_progress.set(0)
        
        # Run training in background
        thread = threading.Thread(target=self._train_models_background)
        thread.start()
    
    def _train_models_background(self):
        """Background training of models."""
        try:
            # Get training data from database
            if not self.db_manager:
                self.after(0, lambda: messagebox.showerror("Error", "Database not available"))
                return
            
            # Update progress
            self.after(0, lambda: self.train_progress.set(0.1))
            
            # Get recent data for training
            results = self.db_manager.get_historical_data(days_back=30)
            
            if not results or len(results) < 100:
                self.after(0, lambda: messagebox.showwarning(
                    "Insufficient Data", 
                    f"Need at least 100 records for training. Found: {len(results) if results else 0}"
                ))
                # Re-enable button before returning
                self.after(0, lambda: self.train_btn.configure(state="normal", text="Train All Models"))
                self.after(0, lambda: self.train_progress.set(0))
                return
            
            # Prepare data once for all models
            self.after(0, lambda: self.train_progress.set(0.2))
            training_data = self._prepare_training_data(results)
            
            if training_data is None or len(training_data) == 0:
                self.logger.error("Failed to prepare training data")
                self.after(0, lambda: messagebox.showerror(
                    "Data Preparation Error", 
                    "Failed to prepare training data. Check logs for details."
                ))
                # Re-enable button before returning
                self.after(0, lambda: self.train_btn.configure(state="normal", text="Train All Models"))
                self.after(0, lambda: self.train_progress.set(0))
                return
            
            self.logger.info(f"Prepared {len(training_data)} training samples")
            
            # Train each model
            models = ['threshold_optimizer', 'failure_predictor', 'drift_detector']
            failed_models = []
            
            for i, model_name in enumerate(models):
                progress = 0.2 + (i + 1) * 0.25
                self.after(0, lambda p=progress: self.train_progress.set(p))
                
                # Train model using ML manager
                if hasattr(self.ml_manager, 'train_model'):
                    try:
                        self.logger.info(f"Training {model_name}...")
                        result = self.ml_manager.train_model(model_name, training_data)
                        self.logger.info(f"Training result for {model_name}: {result}")
                        
                        # Save the trained model
                        if self.ml_manager.save_model(model_name):
                            self.logger.info(f"Successfully saved {model_name}")
                        else:
                            self.logger.error(f"Failed to save {model_name}")
                            failed_models.append(model_name)
                    except Exception as e:
                        self.logger.error(f"Error training {model_name}: {e}")
                        failed_models.append(model_name)
                else:
                    self.logger.error(f"ML manager doesn't have train_model method")
                    failed_models.append(model_name)
                
            # Complete
            self.after(0, lambda: self.train_progress.set(1.0))
            
            # Show results
            if failed_models:
                self.after(0, lambda: messagebox.showwarning(
                    "Training Completed with Errors", 
                    f"Failed to train: {', '.join(failed_models)}\n\n"
                    f"Successfully trained: {len(models) - len(failed_models)} models"
                ))
            else:
                self.after(0, lambda: messagebox.showinfo("Success", "All models trained successfully!"))
            
            # Update status - wait a bit for models to save
            self.after(500, self._update_model_status)
            
        except Exception as e:
            self.logger.error(f"Error training models: {e}")
            self.after(0, lambda: messagebox.showerror("Error", f"Training failed: {str(e)}"))
        finally:
            # Re-enable button
            self.after(0, lambda: self.train_btn.configure(state="normal", text="Train All Models"))
            self.after(1000, lambda: self.train_progress.set(0))
    
    def _optimize_thresholds_advanced(self):
        """Advanced threshold optimization."""
        if not self.ml_manager:
            messagebox.showerror("Error", "ML components not available")
            return
        
        # Show optimization dialog
        dialog = ctk.CTkToplevel(self)
        dialog.title("Threshold Optimization")
        dialog.geometry("600x400")
        
        # Header
        ctk.CTkLabel(
            dialog,
            text="Threshold Optimization Settings",
            font=ctk.CTkFont(size=18, weight="bold")
        ).pack(pady=20)
        
        # Options frame
        options_frame = ctk.CTkFrame(dialog)
        options_frame.pack(fill='both', expand=True, padx=20, pady=(0, 20))
        
        # Target metrics
        ctk.CTkLabel(
            options_frame,
            text="Optimization Target:",
            font=ctk.CTkFont(size=14, weight="bold")
        ).pack(anchor='w', padx=20, pady=(20, 10))
        
        target_var = ctk.StringVar(value="balanced")
        targets = [
            ("Balanced (Recommended)", "balanced"),
            ("Minimize False Failures", "min_false_negative"),
            ("Minimize False Passes", "min_false_positive"),
            ("Maximize Yield", "max_yield")
        ]
        
        for text, value in targets:
            ctk.CTkRadioButton(
                options_frame,
                text=text,
                variable=target_var,
                value=value
            ).pack(anchor='w', padx=40, pady=5)
        
        # Model selection
        ctk.CTkLabel(
            options_frame,
            text="Apply to Models:",
            font=ctk.CTkFont(size=14, weight="bold")
        ).pack(anchor='w', padx=20, pady=(20, 10))
        
        model_var = ctk.StringVar(value="all")
        ctk.CTkRadioButton(
            options_frame,
            text="All Models",
            variable=model_var,
            value="all"
        ).pack(anchor='w', padx=40, pady=5)
        
        ctk.CTkRadioButton(
            options_frame,
            text="Specific Model (enter below)",
            variable=model_var,
            value="specific"
        ).pack(anchor='w', padx=40, pady=5)
        
        model_entry = ctk.CTkEntry(options_frame, placeholder_text="e.g., 8340-1")
        model_entry.pack(anchor='w', padx=60, pady=5)
        
        # Buttons
        button_frame = ctk.CTkFrame(dialog)
        button_frame.pack(fill='x', padx=20, pady=20)
        
        def run_optimization():
            target = target_var.get()
            apply_to = model_var.get()
            specific_model = model_entry.get() if apply_to == "specific" else None
            
            dialog.destroy()
            
            # Run optimization in background
            self.after(100, lambda: self._run_threshold_optimization(target, specific_model))
        
        ctk.CTkButton(
            button_frame,
            text="Run Optimization",
            command=run_optimization,
            width=150
        ).pack(side='left', padx=10)
        
        ctk.CTkButton(
            button_frame,
            text="Cancel",
            command=dialog.destroy,
            width=100
        ).pack(side='left')
    
    def _view_current_thresholds(self):
        """View current threshold settings."""
        self.model_details.delete("1.0", "end")
        self.model_details.insert("1.0", "Current Threshold Settings\n" + "="*50 + "\n\n")
        
        try:
            if self.db_manager:
                # Get unique models from recent data
                results = self.db_manager.get_historical_data(days_back=7, limit=100)
                models = set()
                for r in results:
                    if r.model:
                        models.add(r.model)
                
                if models:
                    self.model_details.insert("end", "Model-Specific Thresholds:\n\n")
                    
                    # Get actual thresholds used for each model
                    for model in sorted(models):
                        self.model_details.insert("end", f"{model}:\n")
                        
                        # Calculate actual threshold based on model type
                        if model == '8340-1':
                            sigma_threshold = 0.4  # Fixed threshold for this model
                            self.model_details.insert("end", f"  ‚Ä¢ Sigma Gradient: {sigma_threshold:.3f} (fixed)\n")
                        elif model.startswith('8555'):
                            base_threshold = 0.0015
                            self.model_details.insert("end", f"  ‚Ä¢ Sigma Gradient: {base_threshold:.4f} √ó spec factor\n")
                        else:
                            # Default formula-based threshold
                            self.model_details.insert("end", f"  ‚Ä¢ Sigma Gradient: (spec/length) √ó 12.0\n")
                        
                        self.model_details.insert("end", f"  ‚Ä¢ Linearity Spec: Model-specific\n")
                        self.model_details.insert("end", f"  ‚Ä¢ Resistance Tolerance: ¬±10%\n\n")
                        
                        # Show if we have optimized thresholds
                        if hasattr(self, '_optimized_thresholds') and model in self._optimized_thresholds:
                            self.model_details.insert("end", f"  ‚úì Optimized: {self._optimized_thresholds[model]:.4f}\n\n")
                else:
                    self.model_details.insert("end", "No models found in recent data.\n")
            else:
                self.model_details.insert("end", "Database not available.\n")
                
            self.model_details.insert("end", "\nDefault Thresholds:\n")
            self.model_details.insert("end", "  ‚Ä¢ Sigma Gradient: 0.050\n")
            self.model_details.insert("end", "  ‚Ä¢ Range Utilization: 85%\n")
            self.model_details.insert("end", "  ‚Ä¢ Risk Threshold: 0.075\n")
            
        except Exception as e:
            self.logger.error(f"Error viewing thresholds: {e}")
            self.model_details.insert("end", f"\nError: {str(e)}\n")
    
    def _show_model_details(self, model_name):
        """Show detailed information about a specific model."""
        self.model_details.delete("1.0", "end")
        self.model_details.insert("1.0", f"{model_name} Details\n" + "="*50 + "\n\n")
        
        try:
            if self.ml_manager:
                # Get model info
                if model_name == "Threshold Optimizer":
                    info = self.ml_manager.get_model_info('threshold_optimizer')
                elif model_name == "Failure Predictor":
                    info = self.ml_manager.get_model_info('failure_predictor')
                elif model_name == "Drift Detector":
                    info = self.ml_manager.get_model_info('drift_detector')
                else:
                    info = None
                
                if info:
                    self.model_details.insert("end", f"Status: {'Trained' if info.get('is_trained') else 'Not Trained'}\n")
                    if info.get('is_trained'):
                        self.model_details.insert("end", f"Last Trained: {info.get('training_date', 'Unknown')}\n")
                        self.model_details.insert("end", f"Training Samples: {info.get('n_samples', 0)}\n")
                        self.model_details.insert("end", f"Accuracy: {info.get('accuracy', 0):.1f}%\n\n")
                        
                        self.model_details.insert("end", "Performance Metrics:\n")
                        metrics = info.get('metrics', {})
                        for metric, value in metrics.items():
                            self.model_details.insert("end", f"  ‚Ä¢ {metric}: {value}\n")
                    else:
                        self.model_details.insert("end", "\nModel not trained. Click 'Train All Models' to train.\n")
                else:
                    self.model_details.insert("end", "Model information not available.\n")
            else:
                self.model_details.insert("end", "ML components not available.\n")
                
            # Add model description
            self.model_details.insert("end", "\nDescription:\n")
            if model_name == "Threshold Optimizer":
                self.model_details.insert("end", 
                    "Analyzes historical pass/fail data to determine optimal thresholds "
                    "that minimize false failures while maintaining quality standards. "
                    "Reduces unnecessary rejections by up to 20%.")
            elif model_name == "Failure Predictor":
                self.model_details.insert("end", 
                    "Predicts potential failures based on early measurement indicators. "
                    "Enables proactive quality control by identifying at-risk units "
                    "before final testing.")
            elif model_name == "Drift Detector":
                self.model_details.insert("end", 
                    "Monitors manufacturing process for gradual changes or drift. "
                    "Alerts when process parameters shift outside normal ranges, "
                    "enabling early intervention.")
                    
        except Exception as e:
            self.logger.error(f"Error showing model details: {e}")
            self.model_details.insert("end", f"\nError: {str(e)}\n")
    
    def _prepare_training_data(self, results) -> Optional[pd.DataFrame]:
        """Prepare training data from analysis results for ML models."""
        self.logger.info(f"Starting data preparation with {len(results)} results")
        try:
            # Pre-calculate model statistics to avoid repeated database queries
            model_pass_rates = {}
            unique_models = set(r.model for r in results)
            
            self.logger.info(f"Pre-calculating pass rates for {len(unique_models)} models")
            for model in unique_models:
                model_pass_rates[model] = self._calculate_model_pass_rate_cached(model, results)
            
            # Convert results to dataframe format
            data_rows = []
            
            for result in results:
                if hasattr(result, 'tracks') and result.tracks:
                    for track in result.tracks:
                        row = {
                            # Basic info
                            'model': result.model,
                            'serial': result.serial,
                            'timestamp': result.timestamp,
                            
                            # Key measurements - using actual database attributes
                            'sigma_gradient': track.sigma_gradient if hasattr(track, 'sigma_gradient') else 0,
                            'linearity_error': track.final_linearity_error_shifted if hasattr(track, 'final_linearity_error_shifted') else 0,
                            'resistance_change': track.resistance_change if hasattr(track, 'resistance_change') else 0,
                            'travel_length': track.travel_length if hasattr(track, 'travel_length') else 0,
                            'unit_length': track.unit_length if hasattr(track, 'unit_length') else 0,
                            
                            # Thresholds and specs - ACTUAL VALUES FROM DATA
                            'linearity_spec': track.linearity_spec if hasattr(track, 'linearity_spec') else 1.0,
                            'resistance_tolerance': 10.0,  # Standard tolerance
                            'sigma_threshold': track.sigma_threshold if hasattr(track, 'sigma_threshold') else 0.05,  # ACTUAL model-specific threshold
                            
                            # Results
                            'overall_status': track.status.value if hasattr(track.status, 'value') else str(track.status),
                            'risk_category': track.risk_category.value if hasattr(track.risk_category, 'value') else str(track.risk_category),
                            
                            # Additional REAL features for ML - NO FAKE DATA
                            'model_type_encoded': hash(result.model) % 1000,  # Simple encoding
                            'travel_efficiency': track.travel_length / track.unit_length if hasattr(track, 'unit_length') and hasattr(track, 'travel_length') and track.unit_length is not None and track.travel_length is not None and track.unit_length > 0 else 1.0,
                            'resistance_stability': 1.0 - abs(track.resistance_change / track.untrimmed_resistance) if hasattr(track, 'resistance_change') and hasattr(track, 'untrimmed_resistance') and track.resistance_change is not None and track.untrimmed_resistance is not None and track.untrimmed_resistance > 0 else 1.0,
                            'spec_margin': (track.linearity_spec - abs(track.final_linearity_error_shifted)) / track.linearity_spec if hasattr(track, 'linearity_spec') and hasattr(track, 'final_linearity_error_shifted') and track.linearity_spec is not None and track.final_linearity_error_shifted is not None and track.linearity_spec > 0 else 0.5,
                        }
                        
                        # Calculate REAL derived features from actual data
                        # These will be calculated per model when we have enough data
                        row['historical_pass_rate'] = model_pass_rates.get(result.model, 0.95)
                        row['production_volume'] = 100  # Default volume - would be calculated from production data in real system
                        row['batch_mean_sigma'] = track.sigma_gradient if hasattr(track, 'sigma_gradient') else 0.05
                        row['batch_std_sigma'] = 0.01  # Will be calculated from batch statistics when available
                        
                        data_rows.append(row)
            
            if not data_rows:
                self.logger.error("No valid data rows created from results")
                return None
            
            # Create DataFrame
            df = pd.DataFrame(data_rows)
            
            # Add synthetic targets for training (in production, these would come from actual data)
            # For threshold optimizer - optimal threshold based on current performance
            df['optimal_threshold'] = df.apply(
                lambda row: 0.04 if row['overall_status'] == 'Pass' and row['sigma_gradient'] < 0.04 
                else 0.06 if row['overall_status'] == 'Fail' and row['sigma_gradient'] > 0.06 
                else 0.05, axis=1
            )
            
            # For failure predictor - predict if unit will fail in 90 days
            df['failure_within_90_days'] = df.apply(
                lambda row: 1 if row['risk_category'] == 'High' or row['sigma_gradient'] > 0.08 
                else 0, axis=1
            )
            
            # For drift detector - detect manufacturing drift
            df['drift_detected'] = 0  # Would be calculated from time series analysis
            
            # Add REAL time-based features
            try:
                df['timestamp_encoded'] = pd.to_datetime(df['timestamp']).astype(int) // 10**9
            except Exception as e:
                self.logger.warning(f"Could not encode timestamps: {e}")
                # Use a simple incrementing value as fallback
                df['timestamp_encoded'] = range(len(df))
            
            # Calculate rolling statistics per model
            for model in df['model'].unique():
                model_mask = df['model'] == model
                model_data = df[model_mask].sort_values('timestamp')
                
                # Rolling mean difference (detect drift)
                df.loc[model_mask, 'rolling_mean_diff'] = model_data['sigma_gradient'].rolling(window=20, min_periods=1).mean().diff().fillna(0)
                
                # Cumulative deviation from model baseline
                baseline = model_data['sigma_gradient'].iloc[:10].mean() if len(model_data) >= 10 else model_data['sigma_gradient'].mean()
                df.loc[model_mask, 'cumulative_deviation'] = (model_data['sigma_gradient'] - baseline).cumsum()
                
                # Trend slope using linear regression on recent points
                if len(model_data) >= 5:
                    x = np.arange(min(5, len(model_data)))
                    y = model_data['sigma_gradient'].tail(5).values
                    if len(x) == len(y):
                        slope, _ = np.polyfit(x, y, 1)
                        df.loc[model_mask, 'trend_slope'] = slope
                    else:
                        df.loc[model_mask, 'trend_slope'] = 0
                else:
                    df.loc[model_mask, 'trend_slope'] = 0
            
            self.logger.info(f"Prepared training data with {len(df)} samples and {len(df.columns)} features")
            return df
            
        except Exception as e:
            self.logger.error(f"Error preparing training data: {e}")
            import traceback
            self.logger.error(f"Traceback: {traceback.format_exc()}")
            return None
    
    def _run_threshold_optimization(self, target: str, specific_model: Optional[str] = None):
        """Run threshold optimization based on selected target."""
        try:
            # Show progress dialog
            progress_dialog = ctk.CTkToplevel(self)
            progress_dialog.title("Optimizing Thresholds")
            progress_dialog.geometry("400x300")
            
            # Progress display
            progress_text = ctk.CTkTextbox(progress_dialog, height=200)
            progress_text.pack(fill='both', expand=True, padx=20, pady=20)
            
            progress_text.insert("1.0", "Starting threshold optimization...\n\n")
            
            # Get recent data for optimization
            if not self.db_manager:
                progress_text.insert("end", "Error: Database not available\n")
                return
            
            results = self.db_manager.get_historical_data(days_back=30)
            if not results or len(results) < 50:
                progress_text.insert("end", f"Error: Need at least 50 records. Found: {len(results) if results else 0}\n")
                return
            
            progress_text.insert("end", f"Loaded {len(results)} records for analysis\n\n")
            
            # Analyze current performance
            models_data = {}
            for result in results:
                if specific_model and result.model != specific_model:
                    continue
                    
                if result.model not in models_data:
                    models_data[result.model] = {
                        'total': 0, 'pass': 0, 'fail': 0,
                        'sigma_values': [], 'false_failures': 0
                    }
                
                if hasattr(result, 'tracks') and result.tracks:
                    for track in result.tracks:
                        models_data[result.model]['total'] += 1
                        
                        if hasattr(track, 'sigma_gradient'):
                            models_data[result.model]['sigma_values'].append(track.sigma_gradient)
                            
                        if hasattr(track, 'status'):
                            status = track.status.value if hasattr(track.status, 'value') else str(track.status)
                            if status == 'Pass':
                                models_data[result.model]['pass'] += 1
                            else:
                                models_data[result.model]['fail'] += 1
                                
                                # Check if this might be a false failure
                                if track.sigma_gradient < 0.06:  # Current threshold is too strict
                                    models_data[result.model]['false_failures'] += 1
            
            # Optimize thresholds based on target
            optimized_thresholds = {}
            
            for model, data in models_data.items():
                if data['sigma_values']:
                    sigma_array = np.array(data['sigma_values'])
                    current_yield = data['pass'] / data['total'] * 100 if data['total'] > 0 else 0
                    
                    progress_text.insert("end", f"Model {model}:\n")
                    progress_text.insert("end", f"  Current yield: {current_yield:.1f}%\n")
                    progress_text.insert("end", f"  False failures: {data['false_failures']}\n")
                    
                    # Calculate optimal threshold based on target
                    if target == 'balanced':
                        # Balance between yield and quality
                        optimal = np.percentile(sigma_array, 95)
                    elif target == 'min_false_negative':
                        # More conservative - reduce false passes
                        optimal = np.percentile(sigma_array, 90)
                    elif target == 'min_false_positive':
                        # More lenient - reduce false failures
                        optimal = np.percentile(sigma_array, 98)
                    elif target == 'max_yield':
                        # Maximum yield while maintaining basic quality
                        optimal = np.percentile(sigma_array, 99)
                    else:
                        optimal = 0.05  # Default
                    
                    # Ensure threshold is reasonable
                    optimal = max(0.03, min(0.08, optimal))
                    optimized_thresholds[model] = optimal
                    
                    # Calculate impact
                    new_pass = sum(1 for s in sigma_array if s < optimal)
                    new_yield = new_pass / len(sigma_array) * 100
                    yield_improvement = new_yield - current_yield
                    
                    progress_text.insert("end", f"  Optimal threshold: {optimal:.4f}\n")
                    progress_text.insert("end", f"  New yield: {new_yield:.1f}%\n")
                    progress_text.insert("end", f"  Improvement: {yield_improvement:+.1f}%\n\n")
            
            # Summary
            progress_text.insert("end", "Optimization Complete!\n\n")
            progress_text.insert("end", "Recommended Actions:\n")
            
            if optimized_thresholds:
                avg_improvement = np.mean([
                    (sum(1 for s in models_data[m]['sigma_values'] if s < t) / len(models_data[m]['sigma_values']) * 100) -
                    (models_data[m]['pass'] / models_data[m]['total'] * 100)
                    for m, t in optimized_thresholds.items()
                    if m in models_data and models_data[m]['sigma_values']
                ])
                
                progress_text.insert("end", f"‚Ä¢ Apply new thresholds for ~{avg_improvement:.1f}% yield improvement\n")
                progress_text.insert("end", "‚Ä¢ Monitor quality metrics after implementation\n")
                progress_text.insert("end", "‚Ä¢ Re-optimize monthly or after process changes\n")
                
                # Save optimized thresholds
                self._optimized_thresholds = optimized_thresholds
                
                # Add apply button
                apply_btn = ctk.CTkButton(
                    progress_dialog,
                    text="Apply Optimized Thresholds",
                    command=lambda: self._apply_optimized_thresholds(optimized_thresholds, progress_dialog),
                    width=200
                )
                apply_btn.pack(pady=10)
            
            close_btn = ctk.CTkButton(
                progress_dialog,
                text="Close",
                command=progress_dialog.destroy,
                width=100
            )
            close_btn.pack(pady=(0, 10))
            
        except Exception as e:
            self.logger.error(f"Error in threshold optimization: {e}")
            messagebox.showerror("Error", f"Optimization failed: {str(e)}")
    
    def _apply_optimized_thresholds(self, thresholds: Dict[str, float], dialog):
        """Apply the optimized thresholds."""
        try:
            # In a real implementation, this would:
            # 1. Update configuration files
            # 2. Update database threshold settings
            # 3. Notify other components of the change
            
            messagebox.showinfo(
                "Thresholds Applied",
                f"Applied optimized thresholds for {len(thresholds)} models.\n\n"
                "The new thresholds will be used for all future analyses."
            )
            
            # Update the view to show new thresholds
            self._view_current_thresholds()
            
            dialog.destroy()
            
        except Exception as e:
            self.logger.error(f"Error applying thresholds: {e}")
            messagebox.showerror("Error", f"Failed to apply thresholds: {str(e)}")
    
    def _calculate_model_pass_rate_cached(self, model: str, results: List) -> float:
        """Calculate historical pass rate for a specific model using provided results (no DB query)."""
        try:
            model_results = [r for r in results if r.model == model]
            if not model_results:
                return 0.95
            
            total = 0
            passed = 0
            
            for result in model_results:
                if hasattr(result, 'tracks') and result.tracks:
                    for track in result.tracks:
                        total += 1
                        if hasattr(track, 'status'):
                            status = track.status.value if hasattr(track.status, 'value') else str(track.status)
                            if status == 'Pass':
                                passed += 1
            
            return passed / total if total > 0 else 0.95
            
        except Exception as e:
            self.logger.error(f"Error calculating pass rate for {model}: {e}")
            return 0.95
    
    def _calculate_model_pass_rate(self, model: str) -> float:
        """Calculate historical pass rate for a specific model."""
        try:
            if not self.db_manager:
                return 0.95  # Default if no data
            
            # Get last 1000 results for this model
            results = self.db_manager.get_historical_data(days_back=90)
            
            if not results:
                return 0.95
            
            model_results = [r for r in results if r.model == model]
            if not model_results:
                return 0.95
            
            total = 0
            passed = 0
            
            for result in model_results:
                if hasattr(result, 'tracks') and result.tracks:
                    for track in result.tracks:
                        total += 1
                        if hasattr(track, 'status'):
                            status = track.status.value if hasattr(track.status, 'value') else str(track.status)
                            if status == 'Pass':
                                passed += 1
            
            return passed / total if total > 0 else 0.95
            
        except Exception as e:
            self.logger.error(f"Error calculating model pass rate: {e}")
            return 0.95
    
    def _get_model_volume(self, model: str, timestamp: datetime) -> int:
        """Get production volume for a model around the given timestamp."""
        try:
            if not self.db_manager:
                return 100  # Default volume
            
            # Get data within 7 days of the timestamp
            start_date = timestamp - timedelta(days=3)
            end_date = timestamp + timedelta(days=3)
            
            # For now, return count of units processed in that window
            # In production, this would query actual production volume data
            results = self.db_manager.get_historical_data(start_date=start_date, end_date=end_date)
            
            if not results:
                return 100
            
            model_count = sum(1 for r in results if r.model == model)
            return max(model_count, 10)  # Minimum of 10
            
        except Exception as e:
            self.logger.error(f"Error getting model volume: {e}")
            return 100

    def on_show(self):
        """Called when page is shown."""
        self.is_visible = True
        self._update_ml_analytics()
        self._update_model_status()

    def on_hide(self):
        """Called when page is hidden."""
        self.is_visible = False
        self._monitoring = False
        if self._monitor_job:
            self.after_cancel(self._monitor_job)
            self._monitor_job = None

    def cleanup(self):
        """Clean up resources."""
        self.on_hide()